{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQ Prediction with HuBERT using a Deep Neural Net \n",
    "\n",
    "In the last notebook, we used HuBERT layers to predict the PQ Representation of the audio clips in the Perceptual Voice Qualities Database (PVQD). We used a naive aggregation technique to do this (simply averaging over the time steps), but what if instead we decided to try and take advantage of the temporal information to perform prediction? \n",
    "\n",
    "We may *want* to use deep neural networks, because they are super duper cool and powerful, but we have to ask if it is the best tool for the job. Given that the PQ Representation is a vector that represents speaker identity, which can be thought of as the time-invariant characteristics of speech (mostly), will the temporal information increase predictive performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils import *\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 16000\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Load in the HuBERT Model\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bundle = torchaudio.pipelines.HUBERT_BASE\n",
    "hubert_model = bundle.get_model().to(device)\n",
    "\n",
    "print(\"Sample Rate:\", bundle.sample_rate)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Data \n",
    "## Load in the DataFrame\n",
    "y_train = pd.read_csv('../data/pvqd/train_test_split/y_train.csv', index_col=0)\n",
    "y_val = pd.read_csv('../data/pvqd/train_test_split/y_val.csv', index_col=0)\n",
    "\n",
    "# Same inefficient code as before!\n",
    "\n",
    "data_path = \"../data/pvqd/audio_clips/\"\n",
    "audio_files = os.listdir(data_path)\n",
    "speaker_ids = [extract_speaker(audio_file) for audio_file in audio_files]\n",
    "\n",
    "# Assertion to make sure speaker_ids matches y_train['File']\n",
    "i = 0\n",
    "for spk_id in y_train[\"File\"]:\n",
    "    try:\n",
    "        assert spk_id in speaker_ids\n",
    "    except:\n",
    "        print(spk_id)\n",
    "        i+=1\n",
    "\n",
    "# Dictionary to Link Speaker ID to Audio File for O(1) access\n",
    "speaker_file_dict = {}\n",
    "for i in range(0, len(speaker_ids)):\n",
    "    speaker_file_dict[speaker_ids[i]] = os.path.join(data_path, audio_files[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first, we gotta make the data compatible with PyTorch \n",
    "\n",
    "PyTorch is a very powerful package that allows us to process data in fast and remarkable ways. Now, the way to take advantage of PyTorch's [Dataset](https://pytorch.org/tutorials/ beginner/data_loading_tutorial.html) class. Using this class, you can train in parallel, and easily modify batch size (the number of input samples your network considers per training update)\n",
    "\n",
    "Below, we're going to load in the hubert model and implement the class HubertDataset, which will take in a a dataframe of labels, the speaker-to-wavfile array, and a hubert model, and will return the sixth layer of the hubert features and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Implement the Dataset function __getitem__ \n",
    "\n",
    "class HubertDataset(Dataset):\n",
    "    def __init__(self, dataframe, spk_wav_arr, hubert_model):\n",
    "        self.dataframe = dataframe\n",
    "        self.spk_wav_arr = spk_wav_arr # array that links speaker id and \n",
    "        self.hubert_model = hubert_model # the hubert model\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of data samples\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    # TODO: Implement the __getitem__ function\n",
    "    # Given an index, return the features and the labels\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve a single row from the DataFrame\n",
    "        single_row = self.dataframe.iloc[index, :]\n",
    "\n",
    "        # Process the row (assuming you have a function that does this)\n",
    "        left, right, label = self.read_row(single_row)\n",
    "\n",
    "        return left, right, label\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
